# -*- coding: utf-8 -*-
"""Movie_Recommender_System.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/gist/arosha27/379a5dc1a6045b243b3cdff2c19cc5cf/movierecommendersystemproject.ipynb

# ðŸŽ¬ Movie Recommender System
#1. Import and Download Dataset
- Uses kagglehub to download the TMDB 5000 Movie Metadata dataset.

- Reads the CSV files into Pandas DataFrames:

- tmdb_5000_movies.csv

- tmdb_5000_credits.csv
"""

import kagglehub

# Download latest version
path = kagglehub.dataset_download("tmdb/tmdb-movie-metadata")
print("Path to dataset files:", path)

import pandas as pd
import numpy as np

movies = pd.read_csv(f"{path}/tmdb_5000_movies.csv")
credits = pd.read_csv(f"{path}/tmdb_5000_credits.csv")

movies.head(1)

credits.head(1)

"""# 2. Merge Datasets
- Merges the two DataFrames on the "title" column to create a combined dataset.
"""

#combining both the datasets on similar column
movies = movies.merge(credits , on= "title")
movies.head(1).shape

"""# 3. Column Selection for Analysis
- Drops irrelevant columns that do not contribute to content-based recommendation.

- Keeps only important columns:

- movie_id, genres, title, keywords, overview, cast, crew


"""

movies.info()

movies = movies[["movie_id","genres","title","keywords", "overview","cast","crew"]]

movies.head(1)

#or new dataset will have only thress columns like :
#movie_id , title and tag.
#To make the tag,  combine overview , cast , crew , genres , keywords

"""# 4. Data Cleaning
- Drops missing (NaN) entries.

- Removes duplicate rows.


"""

movies.isnull().sum()

movies.dropna(inplace = True)

movies.duplicated().sum()

"""# 5. Feature Engineering â€“ Create â€˜tagsâ€™ Column

## a. Convert JSON-style string columns to Python lists:
   - Converts genres, keywords into lists of names using ast.literal_eval
"""

#now our goal is to preprocess the columns values from our new dataset movies in order to make them in proper format to produce the tag column.

#Let's start with the genres column

movies_genres = movies.iloc[0].genres
movies_genres , type(movies_genres)

#As the genres is a string , so need to change it by ast.eval_literal() to object type in order to traverse on it to get the genres name from it.
import ast

def convert(obj):
  L = []
  for i in ast.literal_eval(obj):
    L.append(i["name"])
  return L

movies["genres"] = movies["genres"].apply(convert)
movies.head()

movies["keywords"] = movies["keywords"].apply(convert)
movies.head()

"""## b. Extract Top 3 Cast Members
   - Parses cast column to get the top 3 actors.
"""

#for cast column to get the top three actors
#change the convert function logic a bit

def convert1(obj):
  L = []
  count = 0
  for i in ast.literal_eval(obj):
    if count!= 3:
      L.append(i["name"])
      count=count+1
    else:
      break;
  return L

movies["cast"] = movies["cast"].apply(convert1)
movies.head()

"""##  c. Extract Director from Crew
   - Filters crew to retain only the directorâ€™s name.
"""

movies["crew"][0]
#we want only the name of the director for that particular movies

def fetch_director(obj):
  L= []
  for i in ast.literal_eval(obj):
    if i["job"] == "Director":
      L.append(i["name"])
      break;
  return L

movies["crew"] = movies["crew"].apply(fetch_director)
movies.head()

"""## d. Split Overview into Words
   - Converts overview into a list of words.


"""

#overview column
#as it a string , we will split it
movies["overview"] = movies["overview"].apply(lambda x : x.split())
movies.head()

"""# 6. Clean Tags â€“ Remove Spaces in Names
Removes internal spaces from all names to avoid confusion between similar names (e.g., "Sam Worthington" vs "Sam Mendes").


"""

movies["genres"] = movies["genres"].apply(lambda x : [i.replace(" " , "") for i in x])
movies["keywords"] = movies["keywords"].apply(lambda x : [i.replace(" " , "") for i in x])
movies["crew"] = movies["crew"].apply(lambda x : [i.replace(" " , "") for i in x])
movies["cast"] = movies["cast"].apply(lambda x : [i.replace(" " , "") for i in x])

movies.head()

"""# 7. Combine Columns into â€˜tagsâ€™
Concatenates overview, genres, keywords, cast, and crew into a new column: tags

"""

movies["tags"] = movies["overview"] + movies["genres"] + movies["keywords"] + movies["cast"] + movies["crew"]
movies.head()

"""# 8. Final Dataset for Modeling
- Creates a new DataFrame new_df with only:

- movie_id, title, tags

- Converts tags from list to string

- Converts all tags to lowercase
"""

new_df = movies[["movie_id" , "title" , "tags"]]

#now we need to convert the tags list into string
new_df["tags"] = new_df["tags"].apply(lambda x : " ".join(x))
new_df["tags"]

new_df["tags"][0]

#converting all the tags value to lowercase as it is a good practice
new_df["tags"] = new_df["tags"].apply(lambda x : x.lower())
new_df.head()

"""# 9. Text Preprocessing â€“ Stemming
Uses NLTKâ€™s PorterStemmer to reduce words to their root form
(e.g., acting â†’ act, actions â†’ action)



"""

import nltk
from nltk.stem.porter import PorterStemmer
ps = PorterStemmer()

#helper function to remove all repetitive words which means same , actions or act or action
def stem(text):
  L = []
  for i in text.split() :
    L.append(ps.stem(i))
  return " ".join(L)

new_df["tags"] = new_df["tags"].apply(stem)

new_df["tags"]

"""# 10. Vectorization â€“ Bag of Words
Uses CountVectorizer to convert tags into vectors (max 5000 features, removes English stopwords
"""

import sklearn
from sklearn.feature_extraction.text import CountVectorizer
cv = CountVectorizer(max_features = 5000 , stop_words= "english")

vectors = cv.fit_transform(new_df["tags"]).toarray()
vectors

cv.get_feature_names_out()[0: 200]

"""# 11. Compute Cosine Similarity Matrix
Calculates cosine similarity between all movie vectors.

This similarity matrix is used for recommendations.

- we have to recommend those five movies whose distance is minimum from the movie entered by the user.
- Using Cosine similarity instead of Eucledian as Eucledian is used for finding tip to tip distance while cosine similarity is used for angle similarity.
"""

from sklearn.metrics.pairwise import cosine_similarity
similarity = cosine_similarity(vectors)

similarity[0] #ist movie's similarity score or distance with all the other movies in the database

"""- Here the logic is we have to find the index of that movie provided by user in the datafram.
- Then find the similarity score matrix for that movie
- sort the similariety score values in descending order
- print the title of ist five movies with high score
"""

new_df["title"]

"""# 12. Recommendation Function
- Defines a function recommend(movie) that:

- Finds the movie index

- Retrieves similarity scores

- Sorts and returns top 5 similar movies


"""

# sorted(similarity[7], reverse = True) #by doing like this , index position will get changed on sorting.
# will use the enumerate to create a tuple of index position and similarity score
#sorted(list(enumerate(similarity[0])),reverse = True , key = lambda x : x[1] )[1:6]

def recommend(movie):
  movie_index = new_df[new_df["title"] == movie].index[0]
  distances = similarity[movie_index]
  five_similar = sorted(list(enumerate(distances)),reverse = True , key = lambda x : x[1])[1:6]

  for i in five_similar:
    print(new_df.iloc[i[0]].title)

recommend("Batman Begins")

"""# 13. Export Artifacts
 - Saves two files using pickle:

 - movies.pkl â†’ contains the final new_df

 - similarity.pkl â†’ contains the cosine similarity matrix
"""

#dumping our new_df where movies names are present to a file names movies.pkl
import pickle
pickle.dump(new_df , open("movies.pkl" , "wb"))

pickle.dump(similarity , open("similarity.pkl","wb")